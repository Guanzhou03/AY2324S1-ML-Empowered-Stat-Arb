{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def get_stock_data(ticker):\n",
    "    stock = yf.download(ticker)\n",
    "    return stock.dropna()\n",
    "\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "stock_data = {ticker: get_stock_data(ticker) for ticker in tickers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 1980-12-12    0.128348    0.128906    0.128348    0.128348    0.099450   \n",
       " 1980-12-15    0.122210    0.122210    0.121652    0.121652    0.094261   \n",
       " 1980-12-16    0.113281    0.113281    0.112723    0.112723    0.087343   \n",
       " 1980-12-17    0.115513    0.116071    0.115513    0.115513    0.089504   \n",
       " 1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092099   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2023-09-01  189.490005  189.919998  188.279999  189.460007  189.460007   \n",
       " 2023-09-05  188.279999  189.979996  187.610001  189.699997  189.699997   \n",
       " 2023-09-06  188.399994  188.850006  181.470001  182.910004  182.910004   \n",
       " 2023-09-07  175.179993  178.210007  173.539993  177.559998  177.559998   \n",
       " 2023-09-08  178.350006  180.240005  177.789993  178.179993  178.179993   \n",
       " \n",
       "                Volume  \n",
       " Date                   \n",
       " 1980-12-12  469033600  \n",
       " 1980-12-15  175884800  \n",
       " 1980-12-16  105728000  \n",
       " 1980-12-17   86441600  \n",
       " 1980-12-18   73449600  \n",
       " ...               ...  \n",
       " 2023-09-01   45732600  \n",
       " 2023-09-05   45280000  \n",
       " 2023-09-06   81755800  \n",
       " 2023-09-07  112488800  \n",
       " 2023-09-08   65551300  \n",
       " \n",
       " [10775 rows x 6 columns],\n",
       " 'MSFT':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 1986-03-13    0.088542    0.101563    0.088542    0.097222    0.060396   \n",
       " 1986-03-14    0.097222    0.102431    0.097222    0.100694    0.062553   \n",
       " 1986-03-17    0.100694    0.103299    0.100694    0.102431    0.063632   \n",
       " 1986-03-18    0.102431    0.103299    0.098958    0.099826    0.062014   \n",
       " 1986-03-19    0.099826    0.100694    0.097222    0.098090    0.060936   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2023-09-01  331.309998  331.989990  326.779999  328.660004  328.660004   \n",
       " 2023-09-05  329.000000  334.850006  328.660004  333.549988  333.549988   \n",
       " 2023-09-06  333.380005  334.459991  330.179993  332.880005  332.880005   \n",
       " 2023-09-07  331.290009  333.079987  329.029999  329.910004  329.910004   \n",
       " 2023-09-08  330.089996  336.160004  329.459991  334.269989  334.269989   \n",
       " \n",
       "                 Volume  \n",
       " Date                    \n",
       " 1986-03-13  1031788800  \n",
       " 1986-03-14   308160000  \n",
       " 1986-03-17   133171200  \n",
       " 1986-03-18    67766400  \n",
       " 1986-03-19    47894400  \n",
       " ...                ...  \n",
       " 2023-09-01    14931200  \n",
       " 2023-09-05    18553900  \n",
       " 2023-09-06    17535800  \n",
       " 2023-09-07    18381000  \n",
       " 2023-09-08    19530100  \n",
       " \n",
       " [9449 rows x 6 columns],\n",
       " 'GOOGL':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 2004-08-19    2.502503    2.604104    2.401401    2.511011    2.511011   \n",
       " 2004-08-20    2.527778    2.729730    2.515015    2.710460    2.710460   \n",
       " 2004-08-23    2.771522    2.839840    2.728979    2.737738    2.737738   \n",
       " 2004-08-24    2.783784    2.792793    2.591842    2.624374    2.624374   \n",
       " 2004-08-25    2.626627    2.702703    2.599600    2.652653    2.652653   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2023-09-01  137.460007  137.460007  134.850006  135.660004  135.660004   \n",
       " 2023-09-05  135.440002  136.419998  134.580002  135.770004  135.770004   \n",
       " 2023-09-06  136.020004  136.529999  133.669998  134.460007  134.460007   \n",
       " 2023-09-07  133.589996  135.580002  132.949997  135.259995  135.259995   \n",
       " 2023-09-08  134.910004  136.660004  134.850006  136.380005  136.380005   \n",
       " \n",
       "                Volume  \n",
       " Date                   \n",
       " 2004-08-19  893181924  \n",
       " 2004-08-20  456686856  \n",
       " 2004-08-23  365122512  \n",
       " 2004-08-24  304946748  \n",
       " 2004-08-25  183772044  \n",
       " ...               ...  \n",
       " 2023-09-01   21524600  \n",
       " 2023-09-05   19403100  \n",
       " 2023-09-06   18684500  \n",
       " 2023-09-07   18844300  \n",
       " 2023-09-08   23558300  \n",
       " \n",
       " [4797 rows x 6 columns],\n",
       " 'AMZN':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 1997-05-15    0.121875    0.125000    0.096354    0.097917    0.097917   \n",
       " 1997-05-16    0.098438    0.098958    0.085417    0.086458    0.086458   \n",
       " 1997-05-19    0.088021    0.088542    0.081250    0.085417    0.085417   \n",
       " 1997-05-20    0.086458    0.087500    0.081771    0.081771    0.081771   \n",
       " 1997-05-21    0.081771    0.082292    0.068750    0.071354    0.071354   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2023-09-01  139.460007  139.960007  136.880005  138.119995  138.119995   \n",
       " 2023-09-05  137.729996  137.800003  135.820007  137.270004  137.270004   \n",
       " 2023-09-06  136.320007  137.449997  134.610001  135.360001  135.360001   \n",
       " 2023-09-07  133.899994  138.029999  133.160004  137.850006  137.850006   \n",
       " 2023-09-08  136.860001  138.850006  136.750000  138.229996  138.229996   \n",
       " \n",
       "                 Volume  \n",
       " Date                    \n",
       " 1997-05-15  1443120000  \n",
       " 1997-05-16   294000000  \n",
       " 1997-05-19   122136000  \n",
       " 1997-05-20   109344000  \n",
       " 1997-05-21   377064000  \n",
       " ...                ...  \n",
       " 2023-09-01    40948300  \n",
       " 2023-09-05    40636700  \n",
       " 2023-09-06    41785500  \n",
       " 2023-09-07    48498900  \n",
       " 2023-09-08    38348200  \n",
       " \n",
       " [6623 rows x 6 columns]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine data of all tickers into one DataFrame\n",
    "combined_data = pd.concat(stock_data, axis=1)\n",
    "\n",
    "# Split the data into training and testing datasets (80% training, 20% testing)\n",
    "train_data, test_data = train_test_split(combined_data, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data)\n",
    "test_scaled = scaler.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_scaled)):\n",
    "    X_train.append(train_scaled[i-60:i])\n",
    "    y_train.append(train_scaled[i])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60, len(test_scaled)):\n",
    "    X_test.append(test_scaled[i-60:i])\n",
    "    y_test.append(test_scaled[i])\n",
    "\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:21:50.284767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:21:50.642441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:21:51.011025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:21:51.259756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:21:51.528850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 9s 25ms/step - loss: nan\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 6s 24ms/step - loss: nan\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: nan\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 7s 25ms/step - loss: nan\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 8s 30ms/step - loss: nan\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 10s 38ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dee50eb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=X_train.shape[2]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: nan\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean(np.square(y_test - predictions))\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2094,) and (4,) not aligned: 2094 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m bounds \u001b[39m=\u001b[39m [(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m stock \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tickers))]\n\u001b[1;32m     23\u001b[0m initial_weights \u001b[39m=\u001b[39m [\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(tickers) \u001b[39mfor\u001b[39;00m stock \u001b[39min\u001b[39;00m tickers]\n\u001b[0;32m---> 25\u001b[0m solution \u001b[39m=\u001b[39m minimize(objective, initial_weights, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m'\u001b[39;49m, bounds\u001b[39m=\u001b[39;49mbounds, constraints\u001b[39m=\u001b[39;49mconstraints)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimal weights:\u001b[39m\u001b[39m\"\u001b[39m, solution\u001b[39m.\u001b[39mx)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_minimize.py:705\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    702\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    703\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    704\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mslsqp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 705\u001b[0m     res \u001b[39m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[1;32m    706\u001b[0m                           constraints, callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    707\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    708\u001b[0m     res \u001b[39m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    709\u001b[0m                                        bounds, constraints,\n\u001b[1;32m    710\u001b[0m                                        callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_slsqp_py.py:374\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    371\u001b[0m     xu[infbnd[:, \u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m    373\u001b[0m \u001b[39m# ScalarFunction provides function and gradient evaluation\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(func, x, jac\u001b[39m=\u001b[39;49mjac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    375\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step,\n\u001b[1;32m    376\u001b[0m                               bounds\u001b[39m=\u001b[39;49mnew_bounds)\n\u001b[1;32m    377\u001b[0m \u001b[39m# gh11403 SLSQP sometimes exceeds bounds by 1 or 2 ULP, make sure this\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39m# doesn't get sent to the func/grad evaluator.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m wrapped_fun \u001b[39m=\u001b[39m _clip_x_for_func(sf\u001b[39m.\u001b[39mfun, new_bounds)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_optimize.py:332\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    328\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[1;32m    330\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    333\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[1;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    160\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(weights):\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39;49mdot(predicted_returns, weights)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2094,) and (4,) not aligned: 2094 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Assuming the predictions are for the closing prices\n",
    "predicted_closes = predictions[:, tickers.index('AAPL')]\n",
    "\n",
    "# Calculate the returns of the predicted prices\n",
    "predicted_returns = np.diff(predicted_closes) / predicted_closes[:-1]\n",
    "\n",
    "# Calculate the covariance matrix of the predicted returns\n",
    "cov_matrix = np.cov(predicted_returns)\n",
    "\n",
    "# Portfolio optimization\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective(weights):\n",
    "    return -np.dot(predicted_returns, weights)\n",
    "\n",
    "constraints = (\n",
    "    {'type': 'eq', 'fun': lambda weights: np.dot(weights, np.ones(len(weights)))},\n",
    "    {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}\n",
    ")\n",
    "\n",
    "bounds = [(-1, 1) for stock in range(len(tickers))]\n",
    "\n",
    "initial_weights = [1./len(tickers) for stock in tickers]\n",
    "\n",
    "solution = minimize(objective, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "print(\"Optimal weights:\", solution.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for ticker in tickers:\n",
    "    scalers[ticker] = MinMaxScaler()\n",
    "    stock_data[ticker] = scalers[ticker].fit_transform(stock_data[ticker])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps)])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 10\n",
    "X_train, y_train = {}, {}\n",
    "for ticker in tickers:\n",
    "    X_train[ticker], y_train[ticker] = prepare_data(stock_data[ticker], time_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:05:27.508651: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-09-10 21:05:27.508693: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-09-10 21:05:27.508708: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-09-10 21:05:27.509108: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-10 21:05:27.509477: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=6))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "models = {}\n",
    "for ticker in tickers:\n",
    "    models[ticker] = create_model((X_train[ticker].shape[1], X_train[ticker].shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AAPL Model\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:05:39.320200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:05:39.743937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:05:40.365452: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:05:41.837182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:05:42.912661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/337 [==============================] - 12s 21ms/step - loss: 8.7511e-04\n",
      "Epoch 2/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 2.3887e-04\n",
      "Epoch 3/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 2.3306e-04\n",
      "Epoch 4/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 2.1962e-04\n",
      "Epoch 5/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.9935e-04\n",
      "Epoch 6/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.9915e-04\n",
      "Epoch 7/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.9549e-04\n",
      "Epoch 8/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.8317e-04\n",
      "Epoch 9/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.7786e-04\n",
      "Epoch 10/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.8299e-04\n",
      "Epoch 11/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.5714e-04\n",
      "Epoch 12/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.6044e-04\n",
      "Epoch 13/50\n",
      "337/337 [==============================] - 7s 20ms/step - loss: 1.5145e-04\n",
      "Epoch 14/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.5059e-04\n",
      "Epoch 15/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.4321e-04\n",
      "Epoch 16/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4563e-04\n",
      "Epoch 17/50\n",
      "337/337 [==============================] - 7s 19ms/step - loss: 1.4421e-04\n",
      "Epoch 18/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4906e-04\n",
      "Epoch 19/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4082e-04\n",
      "Epoch 20/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4025e-04\n",
      "Epoch 21/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3431e-04\n",
      "Epoch 22/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3796e-04\n",
      "Epoch 23/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4001e-04\n",
      "Epoch 24/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3535e-04\n",
      "Epoch 25/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3240e-04\n",
      "Epoch 26/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.4336e-04\n",
      "Epoch 27/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3568e-04\n",
      "Epoch 28/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3426e-04\n",
      "Epoch 29/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3605e-04\n",
      "Epoch 30/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3212e-04\n",
      "Epoch 31/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3121e-04\n",
      "Epoch 32/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3632e-04\n",
      "Epoch 33/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3917e-04\n",
      "Epoch 34/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3236e-04\n",
      "Epoch 35/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3124e-04\n",
      "Epoch 36/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3595e-04\n",
      "Epoch 37/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3051e-04\n",
      "Epoch 38/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3513e-04\n",
      "Epoch 39/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3039e-04\n",
      "Epoch 40/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.2973e-04\n",
      "Epoch 41/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3355e-04\n",
      "Epoch 42/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3115e-04\n",
      "Epoch 43/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3330e-04\n",
      "Epoch 44/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.3030e-04\n",
      "Epoch 45/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.2950e-04\n",
      "Epoch 46/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.2878e-04\n",
      "Epoch 47/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.3558e-04\n",
      "Epoch 48/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.2978e-04\n",
      "Epoch 49/50\n",
      "337/337 [==============================] - 6s 19ms/step - loss: 1.2775e-04\n",
      "Epoch 50/50\n",
      "337/337 [==============================] - 6s 18ms/step - loss: 1.2854e-04\n",
      "Training MSFT Model\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:10:58.815484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:10:59.150128: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:10:59.242269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:10:59.418941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-10 21:10:59.569326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 8s 19ms/step - loss: 0.0024\n",
      "Epoch 2/50\n",
      "295/295 [==============================] - 5s 19ms/step - loss: 2.6202e-04\n",
      "Epoch 3/50\n",
      "295/295 [==============================] - 5s 18ms/step - loss: 2.5234e-04\n",
      "Epoch 4/50\n",
      "295/295 [==============================] - 5s 19ms/step - loss: 2.2845e-04\n",
      "Epoch 5/50\n",
      "295/295 [==============================] - 5s 18ms/step - loss: 2.1853e-04\n",
      "Epoch 6/50\n",
      "295/295 [==============================] - 6s 19ms/step - loss: 2.1608e-04\n",
      "Epoch 7/50\n",
      " 66/295 [=====>........................] - ETA: 4s - loss: 2.4296e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tickers:\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mticker\u001b[39m}\u001b[39;00m\u001b[39m Model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     models[ticker]\u001b[39m.\u001b[39;49mfit(X_train[ticker], y_train[ticker], epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1749\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    625\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    626\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1055\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1108\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for ticker in tickers:\n",
    "    print(f\"Training {ticker} Model\")\n",
    "    models[ticker].fit(X_train[ticker], y_train[ticker], epochs=epochs, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
