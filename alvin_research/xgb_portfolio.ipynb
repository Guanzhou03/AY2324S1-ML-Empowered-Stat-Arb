{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through existing models and load them in\n",
    "PATH= \"models\"\n",
    "ext=\".joblib\"\n",
    "models = {}\n",
    "stocks = []\n",
    "for model in os.listdir(PATH):\n",
    "    file_path = os.path.join(PATH, model)\n",
    "    \n",
    "    # Check if it's a proper model\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1] == ext:\n",
    "        stock = os.path.splitext(file_path)[0].split(\"/\")[1]\n",
    "        stocks.append(stock)\n",
    "        models[stock] = joblib.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xgboost.core.Booster at 0x105d1c910>,\n",
       " <xgboost.core.Booster at 0x103f74f70>,\n",
       " <xgboost.core.Booster at 0x103f74b20>,\n",
       " <xgboost.core.Booster at 0x281d0af70>,\n",
       " <xgboost.core.Booster at 0x281d0afd0>,\n",
       " <xgboost.core.Booster at 0x281d0af10>,\n",
       " <xgboost.core.Booster at 0x281d0aeb0>,\n",
       " <xgboost.core.Booster at 0x281d0ae50>,\n",
       " <xgboost.core.Booster at 0x281d0adc0>,\n",
       " <xgboost.core.Booster at 0x103e40310>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TROW', 'DVN', 'TPR', 'NVR', 'CSCO', 'CE', 'ISRG', 'UAL', 'BA', 'MRO']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2000-01-01'\n",
    "end_date = '2021-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Adj Close\", \"ATR\", \"RSI\", \"Volume\", \"Adj Close_lag1\", \"Adj Close_lag2\"]\n",
    "def generate_data(df, start_date, end_date):\n",
    "    df[\"Adj Close_lag1\"]=df[\"Adj Close\"].shift(1)    \n",
    "    df[\"Adj Close_lag2\"]=df[\"Adj Close\"].shift(2)\n",
    "    df = df[features]    \n",
    "    df = df.dropna()\n",
    "    df = df[start_date:end_date]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = \"/Users/alvin/Documents/GitHub/AY2324S1-ML-Empowered-Stat-Arb/Data/individual_data/\"\n",
    "truth = {}\n",
    "pred = {}\n",
    "indices = None\n",
    "assigned = False\n",
    "for stock in stocks:\n",
    "    stock_df = pd.read_csv(FILEPATH+f\"{stock}.csv\")\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "    stock_df.set_index('Date', inplace=True)\n",
    "    test = generate_data(stock_df, start_date=start_date, end_date=end_date)    \n",
    "    X_test = test.drop(\"Adj Close\", axis=1)\n",
    "    y_test = test[\"Adj Close\"]    \n",
    "    if not assigned:\n",
    "        indices = y_test.index\n",
    "        assigned = True\n",
    "    trained_model = models[stock]\n",
    "    y_pred = trained_model.predict(xgb.DMatrix(X_test))\n",
    "    truth[stock] = y_test\n",
    "    pred[stock] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2009-01-06', '2009-01-07', '2009-01-08', '2009-01-09',\n",
       "               '2009-01-12', '2009-01-13', '2009-01-14', '2009-01-15',\n",
       "               '2009-01-16', '2009-01-20',\n",
       "               ...\n",
       "               '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
       "               '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
       "               '2019-12-30', '2019-12-31'],\n",
       "              dtype='datetime64[ns]', name='Date', length=2766, freq=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({key: pd.Series(value) for key, value in pred.items()})\n",
    "true_df = pd.DataFrame({key: pd.Series(value) for key, value in truth.items()})\n",
    "pred_df.index=indices\n",
    "true_df.index=indices\n",
    "true_df_excluding_last_day = true_df.drop(index = indices[-1])\n",
    "pred_df_excluding_first_day = pred_df.drop(index = indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_portfolio_weights(truth, pred):\n",
    "    index = pred.index\n",
    "    cols = pred.columns\n",
    "    truth_values = truth.values\n",
    "    pred_values = pred.values\n",
    "    res = (pred_values - truth_values)/truth_values\n",
    "    res_sums = np.sum(res, axis=1)[:, np.newaxis]\n",
    "    scaled_res = res/res_sums\n",
    "    weights = pd.DataFrame(data=scaled_res, columns=cols, index=index)\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_weights = generate_portfolio_weights(true_df_excluding_last_day, pred_df_excluding_first_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df_excluding_first_day = true_df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_weights.to_csv(\"weights.csv\")\n",
    "true_df_excluding_first_day.to_csv(\"truth.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
